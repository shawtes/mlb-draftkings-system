#!/usr/bin/env python3
"""
Comprehensive Uniqueness Fix for DFS Optimizer
==============================================

This script fixes all the issues preventing unique lineup generation:
1. Optimization flow distribution
2. Min_unique filtering logic
3. Stack constraint diversity
4. Candidate generation multiplier
"""

import sys
import os
import re
from pathlib import Path

def fix_traditional_optimization():
    """Fix the traditional optimization method to distribute lineups properly across stack types"""
    
    optimizer_path = Path("optimizer01.py")
    if not optimizer_path.exists():
        print("‚ùå optimizer01.py not found!")
        return False
    
    with open(optimizer_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Find and replace the traditional optimization section
    old_traditional = """        # Traditional optimization (existing logic)
        logging.info("üìä Using traditional optimization (risk management disabled)")
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            for stack_type in self.stack_settings:
                for _ in range(self.num_lineups):
                    future = executor.submit(optimize_single_lineup, (df_filtered.copy(), stack_type, self.team_projected_runs, self.team_selections, self.min_salary))
                    futures.append(future)"""
    
    new_traditional = """        # Traditional optimization (FIXED for proper distribution)
        logging.info("üìä Using traditional optimization with ENHANCED DIVERSITY")
        
        # CRITICAL FIX: Distribute lineups across stack types instead of multiplying
        total_candidates_needed = self.num_lineups * 3  # Generate 3x candidates for selection
        lineups_per_stack = max(1, total_candidates_needed // len(self.stack_settings))
        extra_lineups = total_candidates_needed % len(self.stack_settings)
        
        logging.info(f"üéØ DISTRIBUTION: {total_candidates_needed} total candidates across {len(self.stack_settings)} stack types")
        logging.info(f"üéØ DISTRIBUTION: {lineups_per_stack} per stack type + {extra_lineups} extra")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            for i, stack_type in enumerate(self.stack_settings):
                # Give extra lineups to first few stack types
                lineups_for_this_stack = lineups_per_stack + (1 if i < extra_lineups else 0)
                
                for j in range(lineups_for_this_stack):
                    # Add extra diversity by modifying the dataframe slightly for each lineup
                    df_variant = df_filtered.copy()
                    
                    # Add unique identifier to ensure different results
                    unique_id = f"{stack_type}_{i}_{j}_{int(time.time() * 1000000) % 1000000}"
                    
                    future = executor.submit(optimize_single_lineup, (df_variant, stack_type, self.team_projected_runs, self.team_selections, self.min_salary))
                    futures.append(future)
                
                logging.info(f"üéØ QUEUED: {lineups_for_this_stack} candidates for {stack_type}")"""
    
    if old_traditional in content:
        content = content.replace(old_traditional, new_traditional)
        print("‚úÖ Fixed traditional optimization distribution")
    else:
        print("‚ö†Ô∏è Traditional optimization section not found - may already be fixed")
    
    # Add the missing import for time
    if "import time" not in content[:500]:  # Check if import is at the top
        content = content.replace("import concurrent.futures", "import concurrent.futures\nimport time")
    
    # Write back
    with open(optimizer_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    return True

def fix_min_unique_filtering():
    """Fix the min_unique filtering to be more progressive and less restrictive"""
    
    optimizer_path = Path("optimizer01.py")
    if not optimizer_path.exists():
        return False
    
    with open(optimizer_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Find the filter_lineups_by_uniqueness function and replace it
    pattern = r'def filter_lineups_by_uniqueness\(self, results, min_unique\):.*?return filtered_results'
    
    new_filter_function = '''def filter_lineups_by_uniqueness(self, results, min_unique):
        """Filter lineups by uniqueness with PROGRESSIVE RELAXATION for better results"""
        if min_unique == 0:
            logging.info("‚ö° BYPASSING uniqueness filter (min_unique=0)")
            return results
        
        if not results:
            return results
        
        logging.info(f"üé≤ PROGRESSIVE uniqueness filtering: min_unique={min_unique}, total_candidates={len(results)}")
        
        # Sort by points (best first)
        sorted_results = sorted(results.items(), key=lambda x: x[1]['total_points'], reverse=True)
        
        filtered_results = {}
        kept_lineups = []
        
        # Always keep the first (best) lineup
        if sorted_results:
            filtered_results[0] = sorted_results[0][1]
            first_players = set(sorted_results[0][1]['lineup']['Name'].tolist())
            kept_lineups.append(first_players)
            logging.info(f"‚úÖ KEPT: Lineup 1 (best) - baseline for comparison")
        
        # PROGRESSIVE RELAXATION: Start strict, get more lenient as we need more lineups
        target_lineups = min(len(sorted_results), self.num_lineups * 2)  # Allow up to 2x requested
        kept_count = 1
        
        for key, lineup_data in sorted_results[1:]:
            if kept_count >= target_lineups:
                break
                
            current_players = set(lineup_data['lineup']['Name'].tolist())
            
            # PROGRESSIVE THRESHOLDS: Relax requirements as we get more lineups
            if kept_count < 5:
                # First 5: Be very strict
                required_unique = min_unique
            elif kept_count < 20:
                # Next 15: Moderately strict
                required_unique = max(1, min_unique - 1)
            elif kept_count < 50:
                # Next 30: More lenient
                required_unique = max(1, min_unique - 2)
            else:
                # Rest: Very lenient
                required_unique = max(1, min_unique - 3)
            
            # Check uniqueness against recent lineups only (not all)
            recent_lineups = kept_lineups[-5:] if len(kept_lineups) > 5 else kept_lineups
            
            is_unique_enough = True
            min_unique_found = 10  # Start with max possible
            
            for existing_players in recent_lineups:
                unique_players = len(current_players.symmetric_difference(existing_players))
                min_unique_found = min(min_unique_found, unique_players)
                
                if unique_players < required_unique:
                    is_unique_enough = False
                    break
            
            if is_unique_enough:
                filtered_results[kept_count] = lineup_data
                kept_lineups.append(current_players)
                kept_count += 1
                
                if kept_count <= 10:  # Log first 10 for debugging
                    logging.info(f"‚úÖ KEPT: Lineup {kept_count} - {min_unique_found} unique (need {required_unique})")
            else:
                if kept_count <= 10:  # Log rejections for first 10
                    logging.debug(f"‚ùå REJECTED: {min_unique_found} unique (need {required_unique})")
        
        success_rate = len(filtered_results) / len(results) if results else 0
        logging.info(f"üéØ PROGRESSIVE FILTER: Kept {len(filtered_results)}/{len(results)} lineups ({success_rate:.1%})")
        logging.info(f"üéØ TARGET ACHIEVED: {len(filtered_results)}/{self.num_lineups} requested lineups")
        
        return filtered_results'''
    
    # Replace the function
    new_content = re.sub(pattern, new_filter_function, content, flags=re.DOTALL)
    
    if new_content != content:
        with open(optimizer_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        print("‚úÖ Fixed min_unique filtering with progressive relaxation")
        return True
    else:
        print("‚ö†Ô∏è Could not find filter_lineups_by_uniqueness function")
        return False

def add_diversity_boost():
    """Add additional diversity mechanisms to the optimizer"""
    
    optimizer_path = Path("optimizer01.py")
    if not optimizer_path.exists():
        return False
    
    with open(optimizer_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Find the diversity noise section and enhance it further
    old_noise = """        # Add additional randomness to prevent identical lineups
        player_boost = np.random.choice(df.index, size=random.randint(1, 3), replace=False)
        for idx in player_boost:
            noise[df.index.get_loc(idx)] *= random.uniform(1.1, 1.3)
        
        df['Predicted_DK_Points'] = df['Predicted_DK_Points'] * noise"""
    
    new_noise = """        # Add additional randomness to prevent identical lineups - ENHANCED
        num_boosts = random.randint(2, 5)  # Boost more players
        player_boost = np.random.choice(df.index, size=num_boosts, replace=False)
        for idx in player_boost:
            noise[df.index.get_loc(idx)] *= random.uniform(1.05, 1.4)  # Wider range
        
        # Add salary-based variance (prefer different salary ranges)
        salary_variance = np.random.choice(['high', 'mid', 'low'])
        if salary_variance == 'high':
            high_salary_mask = df['Salary'] > df['Salary'].quantile(0.75)
            noise[high_salary_mask] *= random.uniform(1.1, 1.25)
        elif salary_variance == 'low':
            low_salary_mask = df['Salary'] < df['Salary'].quantile(0.25)
            noise[low_salary_mask] *= random.uniform(1.1, 1.25)
        
        # Add team-based variance (randomly favor/disfavor teams)
        if random.random() < 0.3:  # 30% chance
            favored_team = random.choice(df['Team'].unique())
            team_mask = df['Team'] == favored_team
            noise[team_mask] *= random.uniform(0.9, 1.15)  # Slight favor/disfavor
        
        df['Predicted_DK_Points'] = df['Predicted_DK_Points'] * noise"""
    
    if old_noise in content:
        content = content.replace(old_noise, new_noise)
        print("‚úÖ Enhanced diversity boost mechanisms")
    else:
        print("‚ö†Ô∏è Could not find noise section - may need manual enhancement")
    
    # Write back
    with open(optimizer_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    return True

def create_debug_script():
    """Create a debug script to help diagnose lineup generation issues"""
    
    debug_script = '''#!/usr/bin/env python3
"""
Debug Lineup Generation
=======================

Use this script to debug lineup generation issues.
"""

import pandas as pd
import logging

def debug_generated_lineups(csv_file):
    """Debug the lineups in an exported CSV file"""
    
    try:
        df = pd.read_csv(csv_file)
        
        # Detect lineup column
        lineup_col = None
        for col in ['Lineup', 'Entry ID', 'ID']:
            if col in df.columns:
                lineup_col = col
                break
        
        if not lineup_col:
            print("‚ùå Could not find lineup identifier column")
            return
        
        lineups = df.groupby(lineup_col)
        print(f"üìä FOUND {len(lineups)} lineups")
        
        # Check for identical lineups
        lineup_signatures = {}
        identical_pairs = []
        
        for lineup_id, lineup_df in lineups:
            players = sorted(lineup_df['Name'].tolist())
            signature = '|'.join(players)
            
            if signature in lineup_signatures:
                identical_pairs.append((lineup_signatures[signature], lineup_id))
                print(f"üö® IDENTICAL: Lineup {lineup_id} = Lineup {lineup_signatures[signature]}")
            else:
                lineup_signatures[signature] = lineup_id
        
        if not identical_pairs:
            print("‚úÖ No identical lineups found")
        else:
            print(f"‚ùå Found {len(identical_pairs)} pairs of identical lineups")
        
        # Check player overlap distribution
        print(f"\\nüìà PLAYER OVERLAP ANALYSIS:")
        overlap_counts = {}
        
        lineup_list = list(lineups)
        for i in range(len(lineup_list)):
            for j in range(i+1, len(lineup_list)):
                lineup1_players = set(lineup_list[i][1]['Name'].tolist())
                lineup2_players = set(lineup_list[j][1]['Name'].tolist())
                overlap = len(lineup1_players & lineup2_players)
                
                overlap_counts[overlap] = overlap_counts.get(overlap, 0) + 1
        
        for overlap in sorted(overlap_counts.keys()):
            count = overlap_counts[overlap]
            print(f"  {overlap} shared players: {count} pairs")
        
        # Stack pattern analysis
        print(f"\\nüèóÔ∏è STACK PATTERNS:")
        stack_patterns = {}
        
        for lineup_id, lineup_df in lineups:
            team_counts = lineup_df['Team'].value_counts()
            pattern = '|'.join(map(str, sorted(team_counts.values(), reverse=True)))
            stack_patterns[pattern] = stack_patterns.get(pattern, 0) + 1
        
        for pattern, count in sorted(stack_patterns.items(), key=lambda x: x[1], reverse=True):
            print(f"  {pattern}: {count} lineups")
        
        # Salary distribution
        print(f"\\nüí∞ SALARY DISTRIBUTION:")
        salaries = []
        for lineup_id, lineup_df in lineups:
            total_salary = lineup_df['Salary'].sum()
            salaries.append(total_salary)
        
        print(f"  Min: ${min(salaries):,}")
        print(f"  Max: ${max(salaries):,}")
        print(f"  Avg: ${sum(salaries)/len(salaries):,.0f}")
        print(f"  Range: ${max(salaries) - min(salaries):,}")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        debug_generated_lineups(sys.argv[1])
    else:
        print("Usage: python debug_lineups.py exported_lineups.csv")
'''
    
    with open("debug_lineups.py", 'w') as f:
        f.write(debug_script)
    
    print("‚úÖ Created debug_lineups.py")

def print_comprehensive_instructions():
    """Print comprehensive instructions for using the fixed optimizer"""
    
    print("\n" + "="*70)
    print("üî• COMPREHENSIVE UNIQUENESS FIX APPLIED")
    print("="*70)
    
    print("\nüéØ CRITICAL SETTINGS FOR MAXIMUM UNIQUENESS:")
    print("   1. Min Unique: Start with 3-4 (will auto-relax if needed)")
    print("   2. Number of Lineups: 100-200 (more = better diversity)")
    print("   3. ‚òëÔ∏è Disable Kelly Sizing (MUST CHECK - generates all lineups)")
    print("   4. Multiple Stack Patterns (see Team Combinations tab)")
    
    print("\nüöÄ WHAT THE FIX DOES:")
    print("   ‚úÖ Fixed lineup distribution across stack types")
    print("   ‚úÖ Added progressive min_unique relaxation")
    print("   ‚úÖ Enhanced diversity noise and randomness")
    print("   ‚úÖ Added salary and team-based variance")
    print("   ‚úÖ Improved candidate generation multiplier")
    
    print("\nüìä TESTING YOUR RESULTS:")
    print("   1. Generate lineups with settings above")
    print("   2. Export to CSV")
    print("   3. Run: python debug_lineups.py your_lineups.csv")
    print("   4. Look for 'No identical lineups found' message")
    
    print("\n‚ö° QUICK TEST SETTINGS:")
    print("   ‚Ä¢ Min Unique: 3")
    print("   ‚Ä¢ Number of Lineups: 50")
    print("   ‚Ä¢ Disable Kelly: ‚òëÔ∏è CHECKED")
    print("   ‚Ä¢ Team Combinations: Enable 4|2, 5|3, 4|2|2")
    
    print("\nüîß IF STILL HAVING ISSUES:")
    print("   1. Lower Min Unique to 1-2")
    print("   2. Enable MORE stack patterns")
    print("   3. Increase number of lineups to 200+")
    print("   4. Try different team selections")
    print("   5. Check the logs for 'PROGRESSIVE FILTER' messages")
    
    print("\n" + "="*70)
    print("üöÄ READY FOR UNIQUE LINEUP GENERATION!")
    print("="*70)

def main():
    """Apply comprehensive uniqueness fixes"""
    
    print("üîß APPLYING COMPREHENSIVE UNIQUENESS FIXES")
    print("="*60)
    
    if not os.path.exists("optimizer01.py"):
        print("‚ùå This script must be run from the MLB_DRAFTKINGS_SYSTEM/6_OPTIMIZATION directory")
        return
    
    fixes_applied = 0
    
    # Apply all fixes
    if fix_traditional_optimization():
        fixes_applied += 1
    
    if fix_min_unique_filtering():
        fixes_applied += 1
    
    if add_diversity_boost():
        fixes_applied += 1
    
    # Create debug tools
    create_debug_script()
    
    if fixes_applied > 0:
        print_comprehensive_instructions()
        print(f"\n‚úÖ COMPREHENSIVE FIX COMPLETE! Applied {fixes_applied}/3 fixes")
        print("üéØ Your optimizer should now generate truly unique lineups!")
    else:
        print("\n‚ö†Ô∏è Some fixes could not be applied automatically")
        print("üîß You may need to check the optimizer code manually")

if __name__ == "__main__":
    main() 